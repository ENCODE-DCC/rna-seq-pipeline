include required(classpath("application"))

backend {
  default = "Local"
  providers {

    slurm_singularity {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30"
        concurrent-job-limit = 50
        runtime-attributes = """
          Int cpu = 1
          Int? gpu
          Int? time
          Int? memory_mb
          String? slurm_partition
          String? slurm_account
          String? slurm_extra_param
          String singularity_container
          String? singularity_options
          String singularity_command = "exec"
          String? singularity_command_options
        """
        submit = """
          sbatch \
          --export=ALL \
          -J ${job_name} \
          -D ${cwd} \
          -o ${out} \
          -e ${err} \
          ${"-t " + time*60} \
          -n 1 \
          --ntasks-per-node=1 \
          ${"--cpus-per-task=" + cpu} \
          ${"--mem=" + memory_mb} \
          ${"-p " + slurm_partition} \
          ${"--account " + slurm_account} \
          ${"--gres gpu:" + gpu} \
          ${slurm_extra_param} \
          --wrap "chmod u+x ${script} && SINGULARITY_BINDPATH=$(echo ${cwd} | sed 's/cromwell-executions/\n/g' | head -n1) singularity ${singularity_options} ${singularity_command} ${singularity_command_options} ${if defined(gpu) then "--nv" else ""}  ${singularity_container} ${script}"
        """
        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"
      }
    }

    sge_singularity {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30 && sync"
        concurrent-job-limit = 50
        runtime-attributes = """
          String sge_pe = "shm"
          Int cpu = 1
          Int? gpu
          Int? time
          Int? memory_mb
          String? sge_queue
          String? sge_extra_param
          String singularity_container
          String? singularity_options
          String singularity_command = "exec"
          String? singularity_command_options
        """
        submit = """
          echo "chmod u+x ${script} && SINGULARITY_BINDPATH=$(echo ${cwd} | sed 's/cromwell-executions/\n/g' | head -n1) singularity ${singularity_options} ${singularity_command} ${singularity_command_options} ${singularity_container} ${script}" | qsub \
          -terse \
          -b n \
          -N ${job_name} \
          -wd ${cwd} \
          -o ${out} \
          -e ${err} \
          ${if cpu>1 then "-pe " + sge_pe + " " + cpu else " "} \
          ${"-l h_vmem=" + memory_mb/cpu + "m"} \
          ${"-l s_vmem=" + memory_mb/cpu + "m"} \
          ${"-l h_rt=" + time*3600} \
          ${"-l s_rt=" + time*3600} \
          ${"-q " + sge_queue} \
          ${"-l gpu=" + gpu} \
          ${sge_extra_param} \
          -V
        """
        kill = "qdel ${job_id}"
        check-alive = "qstat -j ${job_id}"
        job-id-regex = "(\\d+)"
      }
    }

    singularity {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30 && sync"
        concurrent-job-limit = 10
        runtime-attributes = """
          String singularity_container
          String? singularity_options
          String singularity_command = "exec"
          String? singularity_command_options
        """
        submit = """
          chmod u+x ${script} && SINGULARITY_BINDPATH=$(echo ${cwd} | sed 's/cromwell-executions/\n/g' | head -n1) singularity ${singularity_options} \
          ${singularity_command} ${singularity_command_options} \
          ${singularity_container} ${script} & echo $!
        """
        job-id-regex = "(\\d+)"
        check-alive = "ps -ef | grep -v grep | grep ${job_id}"
        kill = "kill -9 ${job_id}"
      }
    }

    Local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        concurrent-job-limit = 10
      }
    }

    sge {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30 && sync"
        concurrent-job-limit = 50
        runtime-attributes = """
        String sge_pe = "shm"
        Int cpu = 1
        Int? gpu
        Int? time
        Int? memory_mb
        String? sge_queue
        String? sge_extra_param
        """
        submit = """
        qsub \
        -terse \
        -b n \
        -N ${job_name} \
        -wd ${cwd} \
        -o ${out} \
        -e ${err} \
        ${if cpu>1 then "-pe " + sge_pe + " " + cpu else " "} \
        ${"-l h_vmem=" + memory_mb/cpu + "m"} \
        ${"-l s_vmem=" + memory_mb/cpu + "m"} \
        ${"-l h_rt=" + time*3600} \
        ${"-l s_rt=" + time*3600} \
        ${"-q " + sge_queue} \
        ${"-l gpu=" + gpu} \
        ${sge_extra_param} \
        -V \
        ${script}
        """
        kill = "qdel ${job_id}"
        check-alive = "qstat -j ${job_id}"
        job-id-regex = "(\\d+)"
      }
    }

    slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30"
        concurrent-job-limit = 50
        runtime-attributes = """
        Int cpu = 1
        Int? gpu
        Int? time
        Int? memory_mb
        String? slurm_partition
        String? slurm_account
        String? slurm_extra_param
        """
        submit = """
        sbatch \
        --export=ALL \
        -J ${job_name} \
        -D ${cwd} \
        -o ${out} \
        -e ${err} \
        ${"-t " + time*60} \
        -n 1 \
        --ntasks-per-node=1 \
        ${"--cpus-per-task=" + cpu} \
        ${"--mem=" + memory_mb} \
        ${"-p " + slurm_partition} \
        ${"--account " + slurm_account} \
        ${"--gres gpu:" + gpu} \
        ${slurm_extra_param} \
        --wrap "/bin/bash ${script}"
        """
        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"
      }
    }

    google {
      actor-factory = "cromwell.backend.impl.jes.JesBackendLifecycleActorFactory"
      config {
        # Google project
        project = "your-project-name"
        # Base bucket for workflow executions
        root = "gs://your-bucket-name"

        concurrent-job-limit = 1000
        genomics-api-queries-per-100-seconds = 1000
        maximum-polling-interval = 600

        genomics {
          auth = "application-default"
          compute-service-account = "default"
          endpoint-url = "https://genomics.googleapis.com/"
          restrict-metadata-access = false
        }

        filesystems {
          gcs {
            auth = "application-default"
          }
        }
      }
    }
  }
}

services {
  LoadController {
    class = "cromwell.services.loadcontroller.impl.LoadControllerServiceActor"
    config {
      # disable it (for login nodes on Stanford SCG, Sherlock)
      control-frequency = 21474834 seconds
    }
  }
}

system {
  abort-jobs-on-terminate = true
  graceful-server-shutdown = true
}

call-caching {
  enabled = false
  invalidate-bad-cache-results = true
}

google {
  application-name = "cromwell"
  auths = [
    {
      name = "application-default"
      scheme = "application_default"
    }
  ]
}